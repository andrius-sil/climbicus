{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from callbacks import get_callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.xception import Xception\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import load_model\n",
    "from tensorboard import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_class_indices(generator, filename):\n",
    "    class_indices_opp = {v:k for k, v in generator.class_indices.items()}\n",
    "    \n",
    "    def save_obj(obj, name ):\n",
    "        with open(name + '.pkl', 'wb') as f:\n",
    "            pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    save_obj(class_indices_opp, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_directories(base_dir):\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    validation_dir = os.path.join(base_dir, 'val')\n",
    "    test_dir = os.path.join(base_dir, 'test')\n",
    "    return train_dir, validation_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/categories_castle_cafe/categories_blurred_3_or_2_class_removed'\n",
    "no_cats = 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_data_generators():\n",
    "    train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    return train_datagen, test_datagen\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_batches(train_datagen, test_datagen, batch_size):\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "    \n",
    "    # TODO: Test generator\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_base(cnn):\n",
    "    if cnn == 'vgg16':\n",
    "        conv_base = VGG16(weights='imagenet',\n",
    "                           include_top=False,\n",
    "                           input_shape=(150, 150, 3))\n",
    "    elif cnn == 'inception':\n",
    "        conv_base = InceptionV3(weights='imagenet',\n",
    "                                 include_top=False,\n",
    "                                 input_shape=(150, 150, 3))\n",
    "    elif cnn == 'xception':\n",
    "        conv_base = Xception(weights='imagenet',\n",
    "                             include_top=False,\n",
    "                             input_shape=(150, 150, 3))\n",
    "    else:\n",
    "        raise ValueError(f'Unknown pre-trained CNN. Got {cnn} whereas vgg16, inception or exception is expected.')\n",
    "    \n",
    "    return conv_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the first 3 steps:\n",
    "\n",
    "    1) Add your custom network on top of an already trained base network.\n",
    "    2) Freeze the base network.\n",
    "    3) Train the part you added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model(pretrained_cnn, no_cats):\n",
    "    conv_base = get_conv_base(pretrained_cnn)\n",
    "    conv_base.trainable = False\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(conv_base)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(Dense(no_cats, activation='softmax'))\n",
    "\n",
    "    print(model.summary())\n",
    "    print(len(model.trainable_weights))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_compile_cnn(cnn, no_cats):\n",
    "    model = get_cnn_model(cnn, no_cats)\n",
    "    model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 114 images belonging to 38 classes.\n",
      "Found 38 images belonging to 38 classes.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 38)                9766      \n",
      "=================================================================\n",
      "Total params: 16,821,862\n",
      "Trainable params: 2,107,174\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/keras/callbacks/tensorboard_v2.py:92: UserWarning: The TensorBoard callback `batch_size` argument (for histogram computation) is deprecated with TensorFlow 2.0. It will be ignored.\n",
      "  warnings.warn('The TensorBoard callback `batch_size` argument '\n",
      "/usr/local/lib/python3.6/site-packages/keras/callbacks/tensorboard_v2.py:97: UserWarning: The TensorBoard callback does not support gradients display when using TensorFlow 2.0. The `write_grads` argument is ignored.\n",
      "  warnings.warn('The TensorBoard callback does not support '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 6s 6s/step - loss: 4.5092 - acc: 0.0000e+00 - val_loss: 3.8781 - val_acc: 0.0263\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 4s 4s/step - loss: 3.4585 - acc: 0.5000 - val_loss: 3.8750 - val_acc: 0.0263\n"
     ]
    }
   ],
   "source": [
    "train_dir, validation_dir, test_dir = get_training_directories(base_dir)\n",
    "\n",
    "train_datagen, test_datagen = get_cnn_data_generators()\n",
    "\n",
    "train_generator, validation_generator = get_image_batches(train_datagen, test_datagen, BATCH_SIZE)\n",
    "\n",
    "save_class_indices(validation_generator, 'class_indices_cafe')\n",
    "\n",
    "model = build_compile_cnn('vgg16', no_cats)\n",
    "\n",
    "callbacks = get_callbacks('vgg16_first_go', model, train_generator, validation_generator)\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "#                               steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "                              steps_per_epoch=1,\n",
    "                              epochs=300,\n",
    "                              verbose=1,\n",
    "                              validation_data=validation_generator,\n",
    "                              callbacks=callbacks\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps: 4-5\n",
    "\n",
    "    4) Unfreeze some layers in the base network.\n",
    "    5) Jointly train both these layers and the part you added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('castle_30_vgg_features_with_data_augmentation.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.trainable_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If loaded in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_trainable = False\n",
    "# for layer in model.get_layer(\"vgg16\")._layers:\n",
    "#     layer.trainable = False\n",
    "#     if layer.name == 'block5_conv1':\n",
    "#         set_trainable = True\n",
    "#     if set_trainable:\n",
    "#         layer.trainable = True\n",
    "#     else:\n",
    "#         layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(model.trainable_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using conv_base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                    epochs=70,\n",
    "                    validation_data=validation_generator,\n",
    "#                     callbacks=[es]\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('castle_cafe_38_fine_tuned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.8):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points\n",
    "\n",
    "plt.plot(epochs, smooth_curve(acc), 'bo', label='Smoothed training acc')\n",
    "plt.plot(epochs, smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, smooth_curve(loss), 'bo', label='Smoothed training loss')\n",
    "plt.plot(epochs, smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = model.predict_generator(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = {'first': [], 'second': []}\n",
    "for i in pred_probs:\n",
    "    indices = i.argsort()[-3:][::-1]\n",
    "    preds['first'].append(indices[0])\n",
    "    preds['second'].append(indices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = []\n",
    "# for i in validation_generator.classes:\n",
    "#     labels.append(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(validation_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffs = [a_i - b_i for a_i, b_i in zip(preds['first'], labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_class_indices_opp = {v:k for k, v in validation_generator.class_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_class_indices = validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_cat(cat, rank):\n",
    "    category_index_model = val_class_indices[str(cat)]\n",
    "#     print('category_index_model: ', category_index_model)\n",
    "    index_in_labels = labels.index(category_index_model)\n",
    "#     print('index_in_labels: ', index_in_labels)\n",
    "#     diff_val = diffs[index_in_labels]\n",
    "#     print('diff: ', diff_val)\n",
    "    pred = preds[rank][index_in_labels]\n",
    "    pred_category = val_class_indices_opp[pred]\n",
    "    return int(pred_category)\n",
    "#     print('pred_category: ', pred_category)\n",
    "    # would like to know the probability here - could then calibrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(mypath):\n",
    "    onlyfiles = [f for f in os.listdir(mypath) if not f.startswith('.')]\n",
    "    return onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_photo(category, number, group):\n",
    "    if group=='test':\n",
    "        category_paths = [f'{base_dir}/test/{i}/' for i in range(1, 38) if os.path.exists(f'{base_dir}/test/{i}/')]\n",
    "        try:\n",
    "            test_img = os.path.join(category_paths[category-1], get_filenames(category_paths[category-1])[number-1])\n",
    "            img = load_img(test_img)\n",
    "        except IndexError:\n",
    "            img = load_img('data/unknown_route.jpg')\n",
    "    elif group=='train':\n",
    "        category_paths = [f'{base_dir}/train/{i}/' for i in range(1, 38) if os.path.exists(f'{base_dir}/test/{i}/')]\n",
    "        test_img = os.path.join(category_paths[category-1], get_filenames(category_paths[category-1])[number-1])\n",
    "        img = load_img(test_img)        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(no_cats, 3, figsize=(15,80))\n",
    "for i in range(0, no_cats):\n",
    "    ax[i, 0].imshow(get_photo(i+1, 1, 'train'))\n",
    "    ax[i, 1].imshow(get_photo((get_pred_cat(i+1, 'first')), 1, 'test'))\n",
    "    ax[i, 2].imshow(get_photo((get_pred_cat(i+1, 'second')), 1, 'test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('castle_30_vgg_fine_tuned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(base_dir, 'test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = {'first': [], 'second': []}\n",
    "for i in pred_probs:\n",
    "    indices = i.argsort()[-3:][::-1]\n",
    "    preds['first'].append(indices[0])\n",
    "    preds['second'].append(indices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(test_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['first']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['second']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(no_cats, 3, figsize=(15,80))\n",
    "# for i in [range(0, no_cats)]:\n",
    "#     ax[i, 0].imshow(get_photo(i+1, 1, 'train'))\n",
    "#     ax[i, 1].imshow(get_photo((get_pred_cat(i+1, 'first')), 1, 'test2'))\n",
    "#     ax[i, 2].imshow(get_photo((get_pred_cat(i+1, 'second')), 1, 'test2'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
